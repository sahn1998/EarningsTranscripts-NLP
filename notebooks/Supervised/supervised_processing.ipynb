{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e73b8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcdd1eba",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1896b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b2c8a",
   "metadata": {},
   "source": [
    "# Data Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "372bf379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_path = Path(f\"../words_TFIDF/\")\n",
    "model_save_path = Path(f\"./models/\")\n",
    "\n",
    "quarters = [\n",
    "    \"Q1-2023\",\n",
    "    \"Q2-2023\",\n",
    "    \"Q3-2023\",\n",
    "    \"Q4-2023\",\n",
    "    \"Q1-2024\",\n",
    "    \"Q2-2024\",\n",
    "    \"Q3-2024\",\n",
    "    \"Q4-2024\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7461b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load TF-IDF for Q1 2025\n",
    "tfidf_df_q12025 = pd.read_csv(f\"{tfidf_path}/tfidf_q1_2025.csv\")\n",
    "\n",
    "# Load TF-IDF for Q1 2023 - Q4 2024\n",
    "tfidf_df_otherq = pd.read_csv(f\"{tfidf_path}/tfidf_non_q1_2025.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ce955",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Recursively find all EPS CSVs under data/\n",
    "eps_files = glob.glob(\"../../data/**/EPS-*.csv\", recursive=True)\n",
    "\n",
    "# Build company-to-DataFrame map (case-insensitive)\n",
    "eps_data = {}\n",
    "\n",
    "for filepath in eps_files:\n",
    "    # Use parent folder name as company name\n",
    "    company_name = os.path.basename(os.path.dirname(filepath))\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['Quarter'] = df['Quarter'].str.strip().str.upper()\n",
    "        df['Company'] = company_name\n",
    "        eps_data[company_name.lower()] = df  # Store using lowercase key\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "\n",
    "# === Load TF-IDF Data ===\n",
    "tfidf_train = pd.read_csv(f\"{tfidf_path}/tfidf_non_q1_2025.csv\")  # Q1 2023 to Q4 2024\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59014065",
   "metadata": {},
   "source": [
    "# Preprocess Train Data\n",
    "Merge EPS data with the current TFIDF data and label.\n",
    "1. Label = 1  if  EPS in current_quarter > EPS in past_quarter\n",
    "2. Label = 0  otherwise (EPS decreased or stayed the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Function to get EPS label (EPS increase between two quarters) ===\n",
    "def get_eps_label(company_name, past_quarter, current_quarter):\n",
    "    key = company_name.lower()\n",
    "    if key not in eps_data:\n",
    "        return None\n",
    "    df = eps_data[key]\n",
    "    try:\n",
    "        eps_before = df.loc[df['Quarter'] == past_quarter.upper(), 'EPS'].values[0]\n",
    "        eps_current = df.loc[df['Quarter'] == current_quarter.upper(), 'EPS'].values[0]\n",
    "        return int(eps_current > eps_before)\n",
    "    except IndexError:\n",
    "        return None\n",
    "    \n",
    "# List of TF-IDF quarters (dash format)\n",
    "quarters_dash = [\n",
    "    \"Q1-2023\",\n",
    "    \"Q2-2023\",\n",
    "    \"Q3-2023\",\n",
    "    \"Q4-2023\",\n",
    "    \"Q1-2024\",\n",
    "    \"Q2-2024\",\n",
    "    \"Q3-2024\",\n",
    "    \"Q4-2024\"\n",
    "]\n",
    "\n",
    "# Convert to EPS-style format \"Q12023, Q22023, Q32023, Q42023\"\n",
    "quarters_eps = [q.replace(\"-\", \"\") for q in quarters_dash]\n",
    "\n",
    "# Collect all labeled training rows\n",
    "all_train_dfs = []\n",
    "\n",
    "for idx in range(len(quarters_dash)):\n",
    "    current_q_dash = quarters_dash[idx]\n",
    "    current_q_eps = quarters_eps[idx]\n",
    "    \n",
    "    if idx == 0:\n",
    "        past_q_eps = \"Q42022\"\n",
    "    else:\n",
    "        past_q_eps = quarters_eps[idx - 1]\n",
    "\n",
    "    # Filter TF-IDF for current quarter\n",
    "    df_train_q = tfidf_train[tfidf_train[\"quarter\"] == current_q_dash].copy()\n",
    "    \n",
    "    # Label with EPS increase between past and current quarter\n",
    "    df_train_q[\"Label\"] = df_train_q[\"company\"].apply(lambda c: get_eps_label(c, past_q_eps, current_q_eps))\n",
    "    df_train_q = df_train_q.dropna(subset=[\"Label\"])\n",
    "\n",
    "    all_train_dfs.append(df_train_q)\n",
    "\n",
    "# Final training data\n",
    "train_df_combined = pd.concat(all_train_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a8084",
   "metadata": {},
   "source": [
    "# Classification\n",
    "We will try to answer: \"Will EPS increase in Q1 2025 compared to Q4 2024?\"\n",
    "\n",
    "- Features: All TFIDF words\n",
    "- Target: Binary (0 = no increase, 1 = increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b08020",
   "metadata": {},
   "source": [
    "# Train Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf0a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop company and quarter\n",
    "df = train_df_combined.drop(columns=[\"company\", \"quarter\"])\n",
    "\n",
    "# 2. Separate features and target\n",
    "X_tfidf = df.drop(columns=[\"Sector\", \"Label\"])  # TF-IDF (1000 cols)\n",
    "y_train = df[\"Label\"].astype(int)\n",
    "\n",
    "# 3. One-hot encode sector\n",
    "encoder = OneHotEncoder(sparse_output = False, handle_unknown='ignore')\n",
    "sector_encoded = encoder.fit_transform(df[[\"Sector\"]])  # must be 2D\n",
    "\n",
    "# 4. Concatenate TF-IDF + Sector features\n",
    "X_train = np.hstack([X_tfidf.values, sector_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff33801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GridSearchCV for Logistic Regression ===\n",
      "Best params: {'C': 0.1}\n",
      "Best CV F1: 0.5813\n",
      "Model saved: best_model_Logistic_Regression.joblib\n",
      "\n",
      "=== GridSearchCV for Random Forest ===\n",
      "Best params: {'max_depth': 10, 'n_estimators': 200}\n",
      "Best CV F1: 0.6785\n",
      "Model saved: best_model_Random_Forest.joblib\n",
      "\n",
      "=== GridSearchCV for XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/exouser/EarningsTranscripts-NLP/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [03:49:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 6, 'n_estimators': 100, 'scale_pos_weight': 2}\n",
      "Best CV F1: 0.6427\n",
      "Model saved: best_model_XGBoost.joblib\n",
      "\n",
      "=== GridSearchCV for KNN ===\n",
      "Best params: {'n_neighbors': 7}\n",
      "Best CV F1: 0.6426\n",
      "Model saved: best_model_KNN.joblib\n",
      "\n",
      "=== GridSearchCV for Linear SVC ===\n",
      "Best params: {'C': 0.1}\n",
      "Best CV F1: 0.5821\n",
      "Model saved: best_model_Linear_SVC.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump\n",
    "\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(class_weight=\"balanced\", max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"scale_pos_weight\": [1, 2]  # for imbalance\n",
    "        }\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    \"Linear SVC\": {\n",
    "        \"model\": LinearSVC(class_weight=\"balanced\", max_iter=2000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Stratified K-Fold setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Run GridSearch for each classifier\n",
    "best_models = []\n",
    "for name, spec in param_grids.items():\n",
    "    print(f\"\\n=== GridSearchCV for {name} ===\")\n",
    "    grid = GridSearchCV(spec[\"model\"], spec[\"params\"], cv=skf, scoring=\"f1\", n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "    print(f\"Best CV F1: {grid.best_score_:.4f}\")\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    best_models.append((name, best_model))\n",
    "\n",
    "    # Save best model\n",
    "    dump(best_model, f\"{model_save_path}/best_model_{name.replace(' ', '_')}.joblib\")\n",
    "    print(f\"Model saved: best_model_{name.replace(' ', '_')}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68aea0b",
   "metadata": {},
   "source": [
    "# Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5071d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'welltower':          Date   EPS Quarter    Company\n",
       " 0  2025-04-28  0.40  Q12025  Welltower\n",
       " 1  2025-02-11  0.19  Q42024  Welltower\n",
       " 2  2024-10-28  0.73  Q32024  Welltower\n",
       " 3  2024-07-29  0.42  Q22024  Welltower\n",
       " 4  2024-04-29  0.22  Q12024  Welltower\n",
       " 5  2024-02-13  0.15  Q42023  Welltower\n",
       " 6  2023-10-30  0.24  Q32023  Welltower\n",
       " 7  2023-07-31  0.20  Q22023  Welltower\n",
       " 8  2023-05-02  0.05  Q12023  Welltower\n",
       " 9  2023-02-15 -0.01  Q42022  Welltower,\n",
       " 'cbre':          Date   EPS Quarter Company\n",
       " 0  2025-04-30  0.41  Q12025    CBRE\n",
       " 1  2025-01-31  1.33  Q42024    CBRE\n",
       " 2  2024-10-31  1.51  Q32024    CBRE\n",
       " 3  2024-07-31  1.52  Q22024    CBRE\n",
       " 4  2024-04-30  0.78  Q12024    CBRE\n",
       " 5  2024-01-31  1.63  Q42023    CBRE\n",
       " 6  2023-10-31  1.33  Q32023    CBRE\n",
       " 7  2023-07-31  1.58  Q22023    CBRE\n",
       " 8  2023-04-30  0.92  Q12023    CBRE\n",
       " 9  2023-01-31  1.16  Q42022    CBRE,\n",
       " 'qualcomm':          Date   EPS Quarter   Company\n",
       " 0  2025-03-31  2.52  Q12025  Qualcomm\n",
       " 1  2024-12-31  2.83  Q42024  Qualcomm\n",
       " 2  2024-09-30  2.57  Q32024  Qualcomm\n",
       " 3  2024-06-30  1.88  Q22024  Qualcomm\n",
       " 4  2024-03-31  2.06  Q12024  Qualcomm\n",
       " 5  2023-12-31  2.46  Q42023  Qualcomm\n",
       " 6  2023-09-30  1.32  Q32023  Qualcomm\n",
       " 7  2023-06-30  1.60  Q22023  Qualcomm\n",
       " 8  2023-03-31  1.52  Q12023  Qualcomm\n",
       " 9  2022-12-31  1.98  Q42022  Qualcomm,\n",
       " 'microsoft':          Date   EPS Quarter    Company\n",
       " 0  2025-04-25  2.94  Q12025  Microsoft\n",
       " 1  2025-01-25  2.45  Q42024  Microsoft\n",
       " 2  2024-10-25  2.69  Q32024  Microsoft\n",
       " 3  2024-07-25  2.69  Q22024  Microsoft\n",
       " 4  2024-04-25  2.94  Q12024  Microsoft\n",
       " 5  2024-01-25  2.45  Q42023  Microsoft\n",
       " 6  2023-10-25  2.69  Q32023  Microsoft\n",
       " 7  2023-07-25  2.69  Q22023  Microsoft\n",
       " 8  2023-04-25  2.45  Q12023  Microsoft\n",
       " 9  2023-01-25  2.30  Q42022  Microsoft,\n",
       " 'visa':          Date   EPS Quarter Company\n",
       " 0  2025-04-29  2.76  Q12025    Visa\n",
       " 1  2025-01-30  2.75  Q42024    Visa\n",
       " 2  2024-10-29  2.71  Q32024    Visa\n",
       " 3  2024-07-23  2.42  Q22024    Visa\n",
       " 4  2024-04-23  2.51  Q12024    Visa\n",
       " 5  2024-01-25  2.41  Q42023    Visa\n",
       " 6  2023-10-24  2.33  Q32023    Visa\n",
       " 7  2023-07-25  2.16  Q22023    Visa\n",
       " 8  2023-04-25  2.09  Q12023    Visa\n",
       " 9  2023-01-26  2.18  Q42022    Visa,\n",
       " 'intel':          Date   EPS Quarter Company\n",
       " 0  2025-03-31 -0.19  Q12025   Intel\n",
       " 1  2024-12-31 -0.03  Q42024   Intel\n",
       " 2  2024-09-30 -3.88  Q32024   Intel\n",
       " 3  2024-06-30 -0.38  Q22024   Intel\n",
       " 4  2024-03-31 -0.09  Q12024   Intel\n",
       " 5  2023-12-31  0.64  Q42023   Intel\n",
       " 6  2023-09-30  0.07  Q32023   Intel\n",
       " 7  2023-06-30  0.35  Q22023   Intel\n",
       " 8  2023-03-31 -0.66  Q12023   Intel\n",
       " 9  2022-12-31 -0.18  Q42022   Intel,\n",
       " 'wellsfargo':          Date   EPS Quarter     Company\n",
       " 0  2025-03-31  1.39  Q12025  WellsFargo\n",
       " 1  2024-12-31  1.42  Q42024  WellsFargo\n",
       " 2  2024-09-30  1.42  Q32024  WellsFargo\n",
       " 3  2024-06-30  1.33  Q22024  WellsFargo\n",
       " 4  2024-03-31  1.20  Q12024  WellsFargo\n",
       " 5  2023-12-31  0.87  Q42023  WellsFargo\n",
       " 6  2023-09-30  1.48  Q32023  WellsFargo\n",
       " 7  2023-06-30  1.25  Q22023  WellsFargo\n",
       " 8  2023-03-31  1.23  Q12023  WellsFargo\n",
       " 9  2022-12-31  0.75  Q42022  WellsFargo,\n",
       " 'tsmc':          Date   EPS Quarter Company\n",
       " 0  2025-03-31  2.12  Q12025    TSMC\n",
       " 1  2024-12-31  2.01  Q42024    TSMC\n",
       " 2  2024-09-30  1.94  Q32024    TSMC\n",
       " 3  2024-06-30  1.48  Q22024    TSMC\n",
       " 4  2024-03-31  1.38  Q12024    TSMC\n",
       " 5  2023-12-31  1.62  Q42023    TSMC\n",
       " 6  2023-09-30  1.29  Q32023    TSMC\n",
       " 7  2023-06-30  1.14  Q22023    TSMC\n",
       " 8  2023-03-31  1.31  Q12023    TSMC\n",
       " 9  2022-12-31  1.50  Q42022    TSMC,\n",
       " '3m':          Date    EPS Quarter Company\n",
       " 0  2025-03-31   2.04  Q12025      3M\n",
       " 1  2024-12-31   1.33  Q42024      3M\n",
       " 2  2024-09-30   2.48  Q32024      3M\n",
       " 3  2024-06-30   2.07  Q22024      3M\n",
       " 4  2024-03-31   1.67  Q12024      3M\n",
       " 5  2023-12-31   1.70  Q42023      3M\n",
       " 6  2023-09-30  -3.74  Q32023      3M\n",
       " 7  2023-06-30 -12.35  Q22023      3M\n",
       " 8  2023-03-31   1.76  Q12023      3M\n",
       " 9  2022-12-31   1.01  Q42022      3M,\n",
       " 'united':          Date   EPS Quarter Company\n",
       " 0  2025-03-31  1.16  Q12025  United\n",
       " 1  2024-12-31  2.97  Q42024  United\n",
       " 2  2024-09-30  2.90  Q32024  United\n",
       " 3  2024-06-30  3.96  Q22024  United\n",
       " 4  2024-03-31 -0.38  Q12024  United\n",
       " 5  2023-12-31  1.82  Q42023  United\n",
       " 6  2023-09-30  3.42  Q32023  United\n",
       " 7  2023-06-30  3.24  Q22023  United\n",
       " 8  2023-03-31 -0.59  Q12023  United\n",
       " 9  2022-12-31  2.61  Q42022  United,\n",
       " 'jpmc':          Date   EPS Quarter Company\n",
       " 0  2025-04-12  4.44  Q12025    JPMC\n",
       " 1  2025-01-12  3.04  Q42024    JPMC\n",
       " 2  2024-10-12  3.12  Q32024    JPMC\n",
       " 3  2024-07-12  3.84  Q22024    JPMC\n",
       " 4  2024-04-12  4.44  Q12024    JPMC\n",
       " 5  2024-01-12  3.04  Q42023    JPMC\n",
       " 6  2023-10-12  3.12  Q32023    JPMC\n",
       " 7  2023-07-12  3.84  Q22023    JPMC\n",
       " 8  2023-04-12  4.10  Q12023    JPMC\n",
       " 9  2023-01-12  3.33  Q42022    JPMC,\n",
       " 'honeywell':          Date   EPS Quarter    Company\n",
       " 0  2025-03-31  2.22  Q12025  HoneyWell\n",
       " 1  2024-12-31  1.96  Q42024  HoneyWell\n",
       " 2  2024-09-30  2.16  Q32024  HoneyWell\n",
       " 3  2024-06-30  2.36  Q22024  HoneyWell\n",
       " 4  2024-03-31  2.23  Q12024  HoneyWell\n",
       " 5  2024-01-26  1.91  Q42023  HoneyWell\n",
       " 6  2023-10-26  2.27  Q32023  HoneyWell\n",
       " 7  2023-07-26  2.23  Q22023  HoneyWell\n",
       " 8  2023-04-28  1.51  Q12023  HoneyWell\n",
       " 9  2023-01-26  2.28  Q42022  HoneyWell,\n",
       " 'americanairlines':          Date   EPS Quarter           Company\n",
       " 0  2025-03-31 -0.72  Q12025  AmericanAirlines\n",
       " 1  2024-12-31  0.94  Q42024  AmericanAirlines\n",
       " 2  2024-09-30 -0.23  Q32024  AmericanAirlines\n",
       " 3  2024-06-30  1.01  Q22024  AmericanAirlines\n",
       " 4  2024-03-31 -0.48  Q12024  AmericanAirlines\n",
       " 5  2023-12-31  0.14  Q42023  AmericanAirlines\n",
       " 6  2023-09-30 -0.83  Q32023  AmericanAirlines\n",
       " 7  2023-06-30  1.88  Q22023  AmericanAirlines\n",
       " 8  2023-03-31  0.02  Q12023  AmericanAirlines\n",
       " 9  2022-12-31  1.34  Q42022  AmericanAirlines,\n",
       " 'equinix':          Date   EPS Quarter  Company\n",
       " 0  2025-04-30  3.50  Q12025  Equinix\n",
       " 1  2025-02-12 -0.14  Q42024  Equinix\n",
       " 2  2024-10-30  3.10  Q32024  Equinix\n",
       " 3  2024-08-07  3.16  Q22024  Equinix\n",
       " 4  2024-05-08  2.43  Q12024  Equinix\n",
       " 5  2024-02-14  2.40  Q42023  Equinix\n",
       " 6  2023-10-25  2.93  Q32023  Equinix\n",
       " 7  2023-08-02  2.21  Q22023  Equinix\n",
       " 8  2023-05-03  2.77  Q12023  Equinix\n",
       " 9  2023-02-15  1.39  Q42022  Equinix,\n",
       " 'proctor':          Date    EPS Quarter  Company\n",
       " 0  2025-03-31  $1.54  Q12025  Proctor\n",
       " 1  2024-12-31  $1.88  Q42024  Proctor\n",
       " 2  2024-09-30  $1.61  Q32024  Proctor\n",
       " 3  2024-06-30  $1.52  Q22024  Proctor\n",
       " 4  2024-03-31  $1.40  Q12024  Proctor\n",
       " 5  2023-12-31  $1.83  Q42023  Proctor\n",
       " 6  2023-09-30  $1.37  Q32023  Proctor\n",
       " 7  2023-06-30  $1.37  Q22023  Proctor\n",
       " 8  2023-03-31  $1.59  Q12023  Proctor\n",
       " 9  2022-12-31  $1.57  Q42022  Proctor,\n",
       " 'netflix':          Date   EPS Quarter  Company\n",
       " 0  2025-04-18  4.42  Q12025  Netflix\n",
       " 1  2025-01-18  2.11  Q42024  Netflix\n",
       " 2  2024-10-18  3.73  Q32024  Netflix\n",
       " 3  2024-07-18  3.29  Q22024  Netflix\n",
       " 4  2024-04-18  4.42  Q12024  Netflix\n",
       " 5  2024-01-18  2.11  Q42023  Netflix\n",
       " 6  2023-10-18  3.73  Q32023  Netflix\n",
       " 7  2023-07-18  3.29  Q22023  Netflix\n",
       " 8  2023-04-18  2.88  Q12023  Netflix\n",
       " 9  2023-01-18  2.88  Q42022  Netflix,\n",
       " 'amd':          Date   EPS Quarter Company\n",
       " 0  2025-03-31  0.44  Q12025     AMD\n",
       " 1  2024-12-31  0.30  Q42024     AMD\n",
       " 2  2024-09-30  0.47  Q32024     AMD\n",
       " 3  2024-06-30  0.16  Q22024     AMD\n",
       " 4  2024-03-31  0.07  Q12024     AMD\n",
       " 5  2023-12-31  0.42  Q42023     AMD\n",
       " 6  2023-09-30  0.18  Q32023     AMD\n",
       " 7  2023-06-30  0.02  Q22023     AMD\n",
       " 8  2023-03-31 -0.09  Q12023     AMD\n",
       " 9  2022-12-31 -0.03  Q42022     AMD,\n",
       " 'boa':          Date   EPS Quarter Company\n",
       " 0  2025-04-15  0.90  Q12025     BoA\n",
       " 1  2025-01-16  0.82  Q42024     BoA\n",
       " 2  2024-10-15  0.81  Q32024     BoA\n",
       " 3  2024-07-16  0.83  Q22024     BoA\n",
       " 4  2024-04-16  0.76  Q12024     BoA\n",
       " 5  2024-01-12  0.35  Q42023     BoA\n",
       " 6  2023-10-17  0.90  Q32023     BoA\n",
       " 7  2023-07-18  0.88  Q22023     BoA\n",
       " 8  2023-04-18  0.94  Q12023     BoA\n",
       " 9  2023-01-13  0.85  Q42022     BoA,\n",
       " 'blackstone':          Date   EPS Quarter     Company\n",
       " 0  2025-04-18  1.11  Q12025  Blackstone\n",
       " 1  2025-01-19  0.91  Q42024  Blackstone\n",
       " 2  2024-10-19  1.02  Q32024  Blackstone\n",
       " 3  2024-07-19  0.58  Q22024  Blackstone\n",
       " 4  2024-04-19  1.11  Q12024  Blackstone\n",
       " 5  2024-01-19  0.21  Q42023  Blackstone\n",
       " 6  2023-10-19  0.73  Q32023  Blackstone\n",
       " 7  2023-07-19  0.79  Q22023  Blackstone\n",
       " 8  2023-04-19  0.11  Q12023  Blackstone\n",
       " 9  2023-01-19  0.74  Q42022  Blackstone,\n",
       " 'nvidia':          Date   EPS Quarter Company\n",
       " 0  2025-04-30  0.76  Q12025  Nvidia\n",
       " 1  2025-01-31  0.89  Q42024  Nvidia\n",
       " 2  2024-10-31  0.78  Q32024  Nvidia\n",
       " 3  2024-07-31  0.67  Q22024  Nvidia\n",
       " 4  2024-04-30  0.60  Q12024  Nvidia\n",
       " 5  2024-01-31  0.49  Q42023  Nvidia\n",
       " 6  2023-10-31  0.37  Q32023  Nvidia\n",
       " 7  2023-07-31  0.25  Q22023  Nvidia\n",
       " 8  2023-04-30  0.08  Q12023  Nvidia\n",
       " 9  2023-01-31  0.05  Q42022  Nvidia,\n",
       " 'delta':          Date   EPS Quarter Company\n",
       " 0  2025-03-31  0.37  Q12025   Delta\n",
       " 1  2024-12-31  1.29  Q42024   Delta\n",
       " 2  2024-09-30  1.97  Q32024   Delta\n",
       " 3  2024-06-30  2.01  Q22024   Delta\n",
       " 4  2024-03-31  0.06  Q12024   Delta\n",
       " 5  2023-12-31  3.18  Q42023   Delta\n",
       " 6  2023-09-30  1.72  Q32023   Delta\n",
       " 7  2023-06-30  2.84  Q22023   Delta\n",
       " 8  2023-03-31 -0.57  Q12023   Delta\n",
       " 9  2022-12-31  1.31  Q42022   Delta,\n",
       " 'asml':          Date    EPS Quarter Company\n",
       " 0  2025-03-31  $6.32  Q12025    ASML\n",
       " 1  2024-12-31  $7.32  Q42024    ASML\n",
       " 2  2024-09-30  $5.81  Q32024    ASML\n",
       " 3  2024-06-30  $4.32  Q22024    ASML\n",
       " 4  2024-03-31  $3.38  Q12024    ASML\n",
       " 5  2023-12-31  $5.63  Q42023    ASML\n",
       " 6  2023-09-30  $5.23  Q32023    ASML\n",
       " 7  2023-06-30  $5.35  Q22023    ASML\n",
       " 8  2023-03-31  $5.31  Q12023    ASML\n",
       " 9  2022-12-31  $4.85  Q42022    ASML,\n",
       " 'southwest':          Date   EPS Quarter    Company\n",
       " 0  2025-03-31 -0.26  Q12025  SouthWest\n",
       " 1  2024-12-31  0.46  Q42024  SouthWest\n",
       " 2  2024-09-30  0.11  Q32024  SouthWest\n",
       " 3  2024-06-30  0.58  Q22024  SouthWest\n",
       " 4  2024-03-31 -0.39  Q12024  SouthWest\n",
       " 5  2023-12-31 -0.36  Q42023  SouthWest\n",
       " 6  2023-09-30  0.31  Q32023  SouthWest\n",
       " 7  2023-06-30  1.08  Q22023  SouthWest\n",
       " 8  2023-03-31 -0.27  Q12023  SouthWest\n",
       " 9  2022-12-31 -0.30  Q42022  SouthWest,\n",
       " 'amtower':          Date   EPS Quarter  Company\n",
       " 0  2025-04-29  1.04  Q12025  AmTower\n",
       " 1  2025-02-25  2.62  Q42024  AmTower\n",
       " 2  2024-10-29 -1.69  Q32024  AmTower\n",
       " 3  2024-07-30  1.92  Q22024  AmTower\n",
       " 4  2024-04-30  1.96  Q12024  AmTower\n",
       " 5  2024-02-27  0.18  Q42023  AmTower\n",
       " 6  2023-10-26  1.26  Q32023  AmTower\n",
       " 7  2023-07-27  1.02  Q22023  AmTower\n",
       " 8  2023-04-26  0.72  Q12023  AmTower\n",
       " 9  2023-02-23 -1.47  Q42022  AmTower,\n",
       " 'meta':          Date   EPS Quarter Company\n",
       " 0  2025-04-24  4.71  Q12025    Meta\n",
       " 1  2025-01-24  4.39  Q42024    Meta\n",
       " 2  2024-10-24  3.88  Q32024    Meta\n",
       " 3  2024-07-24  3.23  Q22024    Meta\n",
       " 4  2024-04-24  4.71  Q12024    Meta\n",
       " 5  2024-01-24  4.39  Q42023    Meta\n",
       " 6  2023-10-24  3.88  Q32023    Meta\n",
       " 7  2023-07-24  3.23  Q22023    Meta\n",
       " 8  2023-04-24  2.20  Q12023    Meta\n",
       " 9  2023-01-24  1.76  Q42022    Meta,\n",
       " 'amazon':          Date   EPS Quarter Company\n",
       " 0  2025-03-31  1.59  Q12025  Amazon\n",
       " 1  2024-12-31  1.86  Q42024  Amazon\n",
       " 2  2024-09-30  1.43  Q32024  Amazon\n",
       " 3  2024-06-30  1.26  Q22024  Amazon\n",
       " 4  2024-03-31  0.98  Q12024  Amazon\n",
       " 5  2023-12-31  1.00  Q42023  Amazon\n",
       " 6  2023-09-30  0.94  Q32023  Amazon\n",
       " 7  2023-06-30  0.65  Q22023  Amazon\n",
       " 8  2023-03-31  0.31  Q12023  Amazon\n",
       " 9  2022-12-31  0.03  Q42022  Amazon,\n",
       " 'uber':          Date   EPS Quarter Company\n",
       " 0  2025-05-07  0.83  Q12025    Uber\n",
       " 1  2025-02-07  3.21  Q42024    Uber\n",
       " 2  2024-11-07  1.20  Q32024    Uber\n",
       " 3  2024-08-08 -0.32  Q22024    Uber\n",
       " 4  2024-05-08 -0.35  Q12024    Uber\n",
       " 5  2024-02-08  0.66  Q42023    Uber\n",
       " 6  2023-11-07  0.10  Q32023    Uber\n",
       " 7  2023-08-08  0.18  Q22023    Uber\n",
       " 8  2023-05-02 -0.08  Q12023    Uber\n",
       " 9  2023-02-08  0.29  Q42022    Uber,\n",
       " 'walmart':          Date    EPS Quarter  Company\n",
       " 0  2025-05-15  $0.56  Q12026  Walmart\n",
       " 1  2025-02-20  $1.65  Q42025  Walmart\n",
       " 2  2024-11-16   0.57  Q32025  Walmart\n",
       " 3  2024-08-17   0.56  Q22025  Walmart\n",
       " 4  2024-05-18   0.63  Q12025  Walmart\n",
       " 5  2024-02-21   0.67  Q42024  Walmart\n",
       " 6  2023-11-16   0.06  Q32024  Walmart\n",
       " 7  2023-08-17   0.97  Q22024  Walmart\n",
       " 8  2023-05-18   0.21  Q12024  Walmart\n",
       " 9  2023-02-21   0.77  Q42023  Walmart,\n",
       " 'citigroup':          Date   EPS Quarter    Company\n",
       " 0  2025-04-12  1.58  Q12025  Citigroup\n",
       " 1  2025-01-12  1.33  Q42024  Citigroup\n",
       " 2  2024-10-12  1.51  Q32024  Citigroup\n",
       " 3  2024-07-12  1.52  Q22024  Citigroup\n",
       " 4  2024-04-12  1.58  Q12024  Citigroup\n",
       " 5  2024-01-12 -1.13  Q42023  Citigroup\n",
       " 6  2023-10-12  1.63  Q32023  Citigroup\n",
       " 7  2023-07-12  1.33  Q22023  Citigroup\n",
       " 8  2023-04-12  2.21  Q12023  Citigroup\n",
       " 9  2023-01-12  1.16  Q42022  Citigroup,\n",
       " 'costco':          Date   EPS Quarter Company\n",
       " 0  2025-05-29  4.28  Q12025  Costco\n",
       " 1  2025-03-07  4.04  Q42024  Costco\n",
       " 2  2024-12-12  5.28  Q32024  Costco\n",
       " 3  2024-10-05  3.78  Q22024  Costco\n",
       " 4  2024-06-01  3.98  Q12024  Costco\n",
       " 5  2024-03-03  3.58  Q42023  Costco\n",
       " 6  2023-12-14  4.86  Q32023  Costco\n",
       " 7  2023-10-06  2.93  Q22023  Costco\n",
       " 8  2023-06-02  3.30  Q12023  Costco\n",
       " 9  2023-03-02  3.07  Q42022  Costco,\n",
       " 'henkel':          Date   EPS Quarter Company\n",
       " 0  2025-05-08  1.54  Q12025  Henkel\n",
       " 1  2025-03-11  1.45  Q42024  Henkel\n",
       " 2  2024-11-10  1.40  Q32024  Henkel\n",
       " 3  2024-08-10  1.25  Q22024  Henkel\n",
       " 4  2024-05-10  1.52  Q12024  Henkel\n",
       " 5  2024-03-11  1.22  Q42023  Henkel\n",
       " 6  2023-11-10  1.34  Q32023  Henkel\n",
       " 7  2023-08-10  1.56  Q22023  Henkel\n",
       " 8  2023-05-10  1.75  Q12023  Henkel\n",
       " 9  2023-03-11  1.34  Q42022  Henkel,\n",
       " 'google':          Date   EPS Quarter Company\n",
       " 0  2025-04-25  1.89  Q12025  Google\n",
       " 1  2025-01-25  1.64  Q42024  Google\n",
       " 2  2024-10-25  1.55  Q32024  Google\n",
       " 3  2024-07-25  1.44  Q22024  Google\n",
       " 4  2024-04-25  1.89  Q12024  Google\n",
       " 5  2024-01-25  1.64  Q42023  Google\n",
       " 6  2023-10-25  1.55  Q32023  Google\n",
       " 7  2023-07-25  1.44  Q22023  Google\n",
       " 8  2023-04-25  1.17  Q12023  Google\n",
       " 9  2023-01-25  1.06  Q42022  Google,\n",
       " 'cushmanwakefield':          Date   EPS Quarter           Company\n",
       " 0  2025-04-30  0.41  Q12025  CushmanWakefield\n",
       " 1  2025-01-31  1.33  Q42024  CushmanWakefield\n",
       " 2  2024-10-31  1.51  Q32024  CushmanWakefield\n",
       " 3  2024-07-31  1.52  Q22024  CushmanWakefield\n",
       " 4  2024-04-30 -0.04  Q12024  CushmanWakefield\n",
       " 5  2024-01-31  1.63  Q42023  CushmanWakefield\n",
       " 6  2023-10-31  1.33  Q32023  CushmanWakefield\n",
       " 7  2023-07-31  1.58  Q22023  CushmanWakefield\n",
       " 8  2023-04-30 -0.04  Q12023  CushmanWakefield\n",
       " 9  2023-01-31  1.16  Q42022  CushmanWakefield,\n",
       " 'morganstanley':          Date   EPS Quarter        Company\n",
       " 0  2025-03-31  2.60  Q12025  MorganStanley\n",
       " 1  2024-12-31  2.23  Q42024  MorganStanley\n",
       " 2  2024-09-30  1.88  Q32024  MorganStanley\n",
       " 3  2024-06-30  1.82  Q22024  MorganStanley\n",
       " 4  2024-03-31  2.02  Q12024  MorganStanley\n",
       " 5  2023-12-31  0.86  Q42023  MorganStanley\n",
       " 6  2023-09-30  1.38  Q32023  MorganStanley\n",
       " 7  2023-06-30  1.24  Q22023  MorganStanley\n",
       " 8  2023-03-31  1.70  Q12023  MorganStanley\n",
       " 9  2022-12-31  1.27  Q42022  MorganStanley,\n",
       " 'skywest':          Date   EPS Quarter  Company\n",
       " 0  2025-03-31  2.42  Q12025  SkyWest\n",
       " 1  2024-12-31  2.34  Q42024  SkyWest\n",
       " 2  2024-09-30  2.16  Q32024  SkyWest\n",
       " 3  2024-06-30  1.82  Q22024  SkyWest\n",
       " 4  2024-03-31  1.45  Q12024  SkyWest\n",
       " 5  2023-12-31  0.32  Q42023  SkyWest\n",
       " 6  2023-09-30  0.55  Q32023  SkyWest\n",
       " 7  2023-06-30  0.35  Q22023  SkyWest\n",
       " 8  2023-03-31 -0.45  Q12023  SkyWest\n",
       " 9  2022-12-31 -0.94  Q42022  SkyWest}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b84918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Function to get EPS label (EPS increase between two quarters) ===\n",
    "def get_eps_label(company_name, past_quarter, current_quarter):\n",
    "    key = company_name.lower()\n",
    "    if key not in eps_data:\n",
    "        return None\n",
    "    df = eps_data[key]\n",
    "    try:\n",
    "        eps_before = df.loc[df['Quarter'] == past_quarter.upper(), 'EPS'].values[0]\n",
    "        eps_current = df.loc[df['Quarter'] == current_quarter.upper(), 'EPS'].values[0]\n",
    "        return int(eps_current > eps_before)\n",
    "    except IndexError:\n",
    "        return None\n",
    "    \n",
    "tfidf_test = pd.read_csv(f\"{tfidf_path}/tfidf_q1_2025.csv\")       # Q1 2025\n",
    "df_test_q = tfidf_test.copy()\n",
    "\n",
    "df_test_q[\"Label\"] = df_test_q[\"company\"].apply(lambda c: get_eps_label(c, \"Q42024\", \"Q12025\"))\n",
    "df_test_q = df_test_q.dropna(subset=[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63e835b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>quarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>accelerating</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>won</th>\n",
       "      <th>wondering</th>\n",
       "      <th>working</th>\n",
       "      <th>workload</th>\n",
       "      <th>world</th>\n",
       "      <th>written</th>\n",
       "      <th>written consent</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3M</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>ConsumerGoods</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.131743</td>\n",
       "      <td>0.202829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029227</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022557</td>\n",
       "      <td>0.096764</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>0.073180</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmericanAirlines</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.125046</td>\n",
       "      <td>0.192519</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.085945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmTower</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>RealEstate</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.020242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.035501</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.022022</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASML</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.020772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.031608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015363</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blackstone</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034651</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BoA</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011459</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.030869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBRE</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>RealEstate</td>\n",
       "      <td>0.034808</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Citigroup</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.023067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Costco</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>ConsumerGoods</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.030715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CushmanWakefield</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>RealEstate</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Delta</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Equinix</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>RealEstate</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026118</td>\n",
       "      <td>0.028010</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028562</td>\n",
       "      <td>0.014443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Google</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Tech</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.026590</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Henkel</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>ConsumerGoods</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014372</td>\n",
       "      <td>0.033181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.086374</td>\n",
       "      <td>0.132980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Intel</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.026301</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047970</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.060031</td>\n",
       "      <td>0.100147</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPMC</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028447</td>\n",
       "      <td>0.039677</td>\n",
       "      <td>0.024427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Meta</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Tech</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.032748</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028474</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Tech</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038559</td>\n",
       "      <td>0.014486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119571</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MorganStanley</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.025725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087582</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Tech</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.054185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048616</td>\n",
       "      <td>0.014309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.074155</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>0.077815</td>\n",
       "      <td>0.036671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Proctor</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>ConsumerGoods</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.028405</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086281</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Qualcomm</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SkyWest</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SouthWest</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>0.032454</td>\n",
       "      <td>0.051439</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.020872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182607</td>\n",
       "      <td>0.011543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TSMC</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052251</td>\n",
       "      <td>0.080445</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Uber</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Tech</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.078019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010197</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>United</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Visa</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011973</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>ConsumerGoods</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>0.053599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>0.017664</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>WellsFargo</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.028258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Welltower</td>\n",
       "      <td>Q1-2025</td>\n",
       "      <td>RealEstate</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows  1003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             company  quarter          Sector   ability      able  accelerate  \\\n",
       "0                 3M  Q1-2025   ConsumerGoods  0.006557  0.000000    0.004447   \n",
       "1             Amazon  Q1-2025             NaN  0.029227  0.050031    0.015855   \n",
       "2                AMD  Q1-2025  Semiconductors  0.000000  0.000000    0.021317   \n",
       "3   AmericanAirlines  Q1-2025        Airlines  0.010984  0.006964    0.000000   \n",
       "4            AmTower  Q1-2025      RealEstate  0.005321  0.020242    0.000000   \n",
       "5               ASML  Q1-2025  Semiconductors  0.016382  0.020772    0.000000   \n",
       "6         Blackstone  Q1-2025         Finance  0.029560  0.023426    0.000000   \n",
       "7                BoA  Q1-2025         Finance  0.011524  0.014612    0.000000   \n",
       "8               CBRE  Q1-2025      RealEstate  0.034808  0.006620    0.000000   \n",
       "9          Citigroup  Q1-2025         Finance  0.019128  0.018191    0.006485   \n",
       "10            Costco  Q1-2025   ConsumerGoods  0.012111  0.030715    0.000000   \n",
       "11  CushmanWakefield  Q1-2025      RealEstate  0.008193  0.000000    0.022222   \n",
       "12             Delta  Q1-2025        Airlines  0.007846  0.007461    0.000000   \n",
       "13           Equinix  Q1-2025      RealEstate  0.013536  0.032183    0.018358   \n",
       "14            Google  Q1-2025            Tech  0.005592  0.026590    0.022752   \n",
       "15            Henkel  Q1-2025   ConsumerGoods  0.000000  0.005452    0.019436   \n",
       "16             Intel  Q1-2025  Semiconductors  0.006914  0.026301    0.009377   \n",
       "17              JPMC  Q1-2025         Finance  0.018990  0.006020    0.000000   \n",
       "18              Meta  Q1-2025            Tech  0.029515  0.032748    0.013343   \n",
       "19         Microsoft  Q1-2025            Tech  0.015511  0.034418    0.014024   \n",
       "20     MorganStanley  Q1-2025             NaN  0.005410  0.025725    0.000000   \n",
       "21           Netflix  Q1-2025            Tech  0.007122  0.054185    0.000000   \n",
       "22            Nvidia  Q1-2025  Semiconductors  0.012535  0.027816    0.011333   \n",
       "23           Proctor  Q1-2025   ConsumerGoods  0.020945  0.019918    0.028405   \n",
       "24          Qualcomm  Q1-2025             NaN  0.000000  0.018404    0.000000   \n",
       "25           SkyWest  Q1-2025             NaN  0.008086  0.038450    0.000000   \n",
       "26         SouthWest  Q1-2025        Airlines  0.032454  0.051439    0.007336   \n",
       "27              TSMC  Q1-2025  Semiconductors  0.000000  0.006509    0.000000   \n",
       "28              Uber  Q1-2025            Tech  0.013673  0.078019    0.000000   \n",
       "29            United  Q1-2025        Airlines  0.030283  0.000000    0.000000   \n",
       "30              Visa  Q1-2025         Finance  0.000000  0.015202    0.016260   \n",
       "31           Walmart  Q1-2025   ConsumerGoods  0.042270  0.053599    0.000000   \n",
       "32        WellsFargo  Q1-2025             NaN  0.018033  0.004287    0.000000   \n",
       "33         Welltower  Q1-2025      RealEstate  0.005514  0.020975    0.007478   \n",
       "\n",
       "    accelerated  accelerating  acceleration    access  ...    window  \\\n",
       "0      0.004849      0.010937      0.004891  0.000000  ...  0.000000   \n",
       "1      0.000000      0.019498      0.008719  0.000000  ...  0.000000   \n",
       "2      0.023246      0.019662      0.000000  0.000000  ...  0.000000   \n",
       "3      0.000000      0.000000      0.000000  0.000000  ...  0.000000   \n",
       "4      0.007870      0.035501      0.015875  0.007455  ...  0.000000   \n",
       "5      0.000000      0.000000      0.000000  0.007650  ...  0.000000   \n",
       "6      0.007286      0.032868      0.000000  0.055215  ...  0.011394   \n",
       "7      0.000000      0.000000      0.011459  0.005381  ...  0.008884   \n",
       "8      0.030887      0.000000      0.000000  0.019505  ...  0.000000   \n",
       "9      0.007072      0.007976      0.000000  0.000000  ...  0.000000   \n",
       "10     0.000000      0.000000      0.000000  0.000000  ...  0.000000   \n",
       "11     0.000000      0.000000      0.000000  0.000000  ...  0.000000   \n",
       "12     0.003868      0.004362      0.000000  0.000000  ...  0.000000   \n",
       "13     0.000000      0.022577      0.000000  0.028445  ...  0.000000   \n",
       "14     0.000000      0.009327      0.000000  0.015668  ...  0.000000   \n",
       "15     0.000000      0.000000      0.021376  0.000000  ...  0.000000   \n",
       "16     0.000000      0.000000      0.000000  0.000000  ...  0.047970   \n",
       "17     0.000000      0.000000      0.000000  0.000000  ...  0.000000   \n",
       "18     0.007275      0.008205      0.007338  0.013783  ...  0.045507   \n",
       "19     0.007646      0.000000      0.038559  0.014486  ...  0.119571   \n",
       "20     0.008001      0.000000      0.000000  0.037895  ...  0.087582   \n",
       "21     0.000000      0.000000      0.000000  0.029933  ...  0.000000   \n",
       "22     0.074155      0.006969      0.012465  0.000000  ...  0.009663   \n",
       "23     0.007744      0.026200      0.015620  0.000000  ...  0.000000   \n",
       "24     0.000000      0.000000      0.000000  0.018074  ...  0.059675   \n",
       "25     0.000000      0.000000      0.000000  0.011328  ...  0.000000   \n",
       "26     0.008000      0.009021      0.000000  0.022732  ...  0.000000   \n",
       "27     0.006073      0.002283      0.000000  0.000000  ...  0.000000   \n",
       "28     0.010111      0.000000      0.010197  0.009578  ...  0.000000   \n",
       "29     0.000000      0.016836      0.000000  0.014142  ...  0.000000   \n",
       "30     0.005910      0.013331      0.011922  0.000000  ...  0.000000   \n",
       "31     0.013892      0.000000      0.007006  0.006580  ...  0.000000   \n",
       "32     0.000000      0.000000      0.000000  0.000000  ...  0.000000   \n",
       "33     0.000000      0.000000      0.008224  0.007724  ...  0.000000   \n",
       "\n",
       "         won  wondering   working  workload     world   written  \\\n",
       "0   0.004912   0.000000  0.022142  0.000000  0.003197  0.131743   \n",
       "1   0.008756   0.000000  0.022557  0.096764  0.034201  0.000000   \n",
       "2   0.000000   0.000000  0.030327  0.073180  0.015328  0.000000   \n",
       "3   0.000000   0.000000  0.021193  0.000000  0.014281  0.125046   \n",
       "4   0.000000   0.020013  0.015401  0.022022  0.010378  0.000000   \n",
       "5   0.000000   0.027382  0.031608  0.000000  0.005325  0.000000   \n",
       "6   0.000000   0.024704  0.014258  0.000000  0.048042  0.000000   \n",
       "7   0.011509   0.004816  0.014823  0.000000  0.037459  0.030869   \n",
       "8   0.010428   0.008727  0.000000  0.000000  0.027154  0.000000   \n",
       "9   0.000000   0.005995  0.023067  0.000000  0.032643  0.000000   \n",
       "10  0.000000   0.015183  0.000000  0.000000  0.000000  0.008111   \n",
       "11  0.012272   0.020541  0.007904  0.000000  0.000000  0.000000   \n",
       "12  0.000000   0.000000  0.005046  0.000000  0.015301  0.000000   \n",
       "13  0.000000   0.000000  0.026118  0.028010  0.019800  0.000000   \n",
       "14  0.000000   0.000000  0.026974  0.000000  0.027265  0.000000   \n",
       "15  0.000000   0.014372  0.033181  0.000000  0.011180  0.086374   \n",
       "16  0.020714   0.034670  0.060031  0.100147  0.013484  0.000000   \n",
       "17  0.028447   0.039677  0.024427  0.000000  0.030864  0.000000   \n",
       "18  0.000000   0.000000  0.028474  0.020358  0.038376  0.009883   \n",
       "19  0.007745   0.012963  0.014963  0.064191  0.015125  0.000000   \n",
       "20  0.008104   0.006782  0.010438  0.000000  0.031654  0.000000   \n",
       "21  0.010669   0.000000  0.041225  0.000000  0.048616  0.014309   \n",
       "22  0.000000   0.000000  0.016124  0.077815  0.036671  0.000000   \n",
       "23  0.086281   0.013128  0.025257  0.000000  0.030636  0.000000   \n",
       "24  0.000000   0.000000  0.000000  0.013348  0.012581  0.000000   \n",
       "25  0.000000   0.020274  0.015602  0.000000  0.015771  0.000000   \n",
       "26  0.000000   0.020342  0.020872  0.000000  0.021098  0.000000   \n",
       "27  0.000000   0.005148  0.007923  0.000000  0.000000  0.052251   \n",
       "28  0.000000   0.000000  0.026382  0.000000  0.046667  0.000000   \n",
       "29  0.000000   0.000000  0.000000  0.000000  0.029531  0.000000   \n",
       "30  0.011973   0.025050  0.011566  0.000000  0.062354  0.000000   \n",
       "31  0.014071   0.017664  0.036248  0.000000  0.009160  0.000000   \n",
       "32  0.013507   0.028258  0.000000  0.000000  0.008793  0.000000   \n",
       "33  0.000000   0.006912  0.010639  0.000000  0.010754  0.000000   \n",
       "\n",
       "    written consent     yield      york  \n",
       "0          0.202829  0.000000  0.000000  \n",
       "1          0.000000  0.000000  0.012474  \n",
       "2          0.000000  0.000000  0.000000  \n",
       "3          0.192519  0.010300  0.085945  \n",
       "4          0.000000  0.007485  0.000000  \n",
       "5          0.000000  0.015363  0.000000  \n",
       "6          0.000000  0.034651  0.000000  \n",
       "7          0.000000  0.000000  0.000000  \n",
       "8          0.000000  0.000000  0.000000  \n",
       "9          0.000000  0.000000  0.000000  \n",
       "10         0.000000  0.000000  0.000000  \n",
       "11         0.000000  0.000000  0.000000  \n",
       "12         0.000000  0.018394  0.000000  \n",
       "13         0.000000  0.028562  0.014443  \n",
       "14         0.000000  0.000000  0.000000  \n",
       "15         0.132980  0.000000  0.000000  \n",
       "16         0.000000  0.038903  0.000000  \n",
       "17         0.000000  0.017809  0.000000  \n",
       "18         0.000000  0.000000  0.000000  \n",
       "19         0.000000  0.000000  0.000000  \n",
       "20         0.000000  0.000000  0.000000  \n",
       "21         0.000000  0.010019  0.000000  \n",
       "22         0.000000  0.000000  0.000000  \n",
       "23         0.000000  0.000000  0.000000  \n",
       "24         0.000000  0.000000  0.000000  \n",
       "25         0.000000  0.011375  0.000000  \n",
       "26         0.000000  0.182607  0.011543  \n",
       "27         0.080445  0.003851  0.000000  \n",
       "28         0.000000  0.000000  0.000000  \n",
       "29         0.000000  0.000000  0.086166  \n",
       "30         0.000000  0.005622  0.000000  \n",
       "31         0.000000  0.000000  0.000000  \n",
       "32         0.000000  0.012683  0.000000  \n",
       "33         0.000000  0.007756  0.000000  \n",
       "\n",
       "[34 rows x 1003 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437de41",
   "metadata": {},
   "source": [
    "# Test Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe9e846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop metadata columns\n",
    "df_test = df_test_q.drop(columns=[\"company\", \"quarter\"])\n",
    "\n",
    "# Separate TF-IDF and sector columns\n",
    "X_test_tfidf = df_test.drop(columns=[\"Sector\", \"Label\"])\n",
    "y_test = df_test[\"Label\"].astype(int)\n",
    "\n",
    "# One-hot encode sector using the same encoder from training\n",
    "sector_test_encoded = encoder.transform(df_test[[\"Sector\"]])  # encoder must be from training\n",
    "\n",
    "# Combine TF-IDF and sector features\n",
    "X_test = np.hstack([X_test_tfidf.values, sector_test_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694857a9",
   "metadata": {},
   "source": [
    "# Load Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feab2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import os\n",
    "\n",
    "model_names = [\"Logistic_Regression\", \"Random_Forest\", \"XGBoost\", \"KNN\", \"Linear_SVC\"]\n",
    "best_models_loaded = []\n",
    "\n",
    "for name in model_names:\n",
    "    model_path = f\"{model_save_path}/best_model_{name}.joblib\"\n",
    "    if os.path.exists(model_path):\n",
    "        model = load(model_path)\n",
    "        best_models_loaded.append((name.replace(\"_\", \" \"), model))\n",
    "    else:\n",
    "        print(f\"[Warning] Model file not found: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28eb77",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7adb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Evaluation on Q1 2025 Test Set ===\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.4848\n",
      "AUC-ROC: 0.5035\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4737    0.5625    0.5143        16\n",
      "           1     0.5333    0.4444    0.4848        18\n",
      "\n",
      "    accuracy                         0.5000        34\n",
      "   macro avg     0.5035    0.5035    0.4996        34\n",
      "weighted avg     0.5053    0.5000    0.4987        34\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  7]\n",
      " [10  8]]\n",
      "\n",
      "=== Random Forest Evaluation on Q1 2025 Test Set ===\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.6531\n",
      "AUC-ROC: 0.5312\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.0625    0.1053        16\n",
      "           1     0.5161    0.8889    0.6531        18\n",
      "\n",
      "    accuracy                         0.5000        34\n",
      "   macro avg     0.4247    0.4757    0.3792        34\n",
      "weighted avg     0.4301    0.5000    0.3953        34\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1 15]\n",
      " [ 2 16]]\n",
      "\n",
      "=== XGBoost Evaluation on Q1 2025 Test Set ===\n",
      "Accuracy: 0.5588\n",
      "F1 Score: 0.6341\n",
      "AUC-ROC: 0.4826\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5455    0.3750    0.4444        16\n",
      "           1     0.5652    0.7222    0.6341        18\n",
      "\n",
      "    accuracy                         0.5588        34\n",
      "   macro avg     0.5553    0.5486    0.5393        34\n",
      "weighted avg     0.5559    0.5588    0.5449        34\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6 10]\n",
      " [ 5 13]]\n",
      "\n",
      "=== KNN Evaluation on Q1 2025 Test Set ===\n",
      "Accuracy: 0.5294\n",
      "F1 Score: 0.6000\n",
      "AUC-ROC: 0.5608\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.3750    0.4286        16\n",
      "           1     0.5455    0.6667    0.6000        18\n",
      "\n",
      "    accuracy                         0.5294        34\n",
      "   macro avg     0.5227    0.5208    0.5143        34\n",
      "weighted avg     0.5241    0.5294    0.5193        34\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6 10]\n",
      " [ 6 12]]\n",
      "\n",
      "=== Linear SVC Evaluation on Q1 2025 Test Set ===\n",
      "Accuracy: 0.5000\n",
      "F1 Score: 0.5405\n",
      "AUC-ROC: 0.5417\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4667    0.4375    0.4516        16\n",
      "           1     0.5263    0.5556    0.5405        18\n",
      "\n",
      "    accuracy                         0.5000        34\n",
      "   macro avg     0.4965    0.4965    0.4961        34\n",
      "weighted avg     0.4982    0.5000    0.4987        34\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  9]\n",
      " [ 8 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in best_models_loaded:\n",
    "    print(f\"\\n=== {name} Evaluation on Q1 2025 Test Set ===\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get predicted probabilities or scores for AUC-ROC\n",
    "    try:\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_prob = model.decision_function(X_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute AUC-ROC for {name}: {e}\")\n",
    "        y_prob = None\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else float(\"nan\")\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC-ROC\": auc\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27ae03fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.482639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.560764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.503472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1 Score   AUC-ROC\n",
       "1        Random Forest  0.500000  0.653061  0.531250\n",
       "2              XGBoost  0.558824  0.634146  0.482639\n",
       "3                  KNN  0.529412  0.600000  0.560764\n",
       "4           Linear SVC  0.500000  0.540541  0.541667\n",
       "0  Logistic Regression  0.500000  0.484848  0.503472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).sort_values(\"F1 Score\", ascending=False)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
